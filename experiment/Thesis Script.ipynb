{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": true
   },
   "outputs": [],
   "source": [
    "from muselsl import stream, list_muses, view, record\n",
    "from multiprocessing import Process\n",
    "from mne import Epochs, find_events\n",
    "from time import time, strftime, gmtime\n",
    "import os\n",
    "from stimulus_presentation import Independentstudy\n",
    "from utils import utils\n",
    "from collections import OrderedDict\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "source": [
    "# Brain response to Affective Images\n",
    "\n",
    "In this notebook, an event related potential (ERP) experiment will be conducted. This experiment is based on the classic oddball paradigm, with a series of images being randomly presented over the course of two minutes through PyschoPy presentation software. There will be positively valenced and neutrally valenced images. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Connect to an EEG Device\n",
    "\n",
    "Make sure that your laptop bluetooth is turned on. Power on the Muse device. \n",
    "\n",
    "Open BlueMuse application (can be downloaded on Github) and connect the Muse device. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Apply the EEG Device and Wait for Signal Quality to Stabilize\n",
    "Once your Muse is connected and streaming data, put it on and run the following code to view the raw EEG data stream.\n",
    "\n",
    "The numbers on the side of the graph indicate the variance of the signal. Wait until this decreases below 10 for all electrodes before proceeding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%matplotlib\n",
    "# On Windows, you may need to run the command %matplotlib tk\n",
    "view()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Define Parameters \n",
    "Modify the variables in the following code chunk to define how long you want to run the experiment and the name of the subject and session you are collecting data from."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "# Define these parameters \n",
    "duration = 120 # in seconds. \n",
    "subject = 1 # unique id for each participant\n",
    "session = 2 # 1 or 2 - represents a data collection session. Multiple trials can be performed for each session"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Run the Experiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seat the subject in front of the computer and run the following cell to run a single trial of the experiment.\n",
    "\n",
    "In order to maximise the possibility of success, participants should take the experiment in a quiet environment and do their best to minimize movement that might contaminate the signal. With their jaw and face relaxed, subjects should focus on the stimuli, mentally noting whether they see a \"face\" or a \"house\".\n",
    "\n",
    "Data will be recorded into CSV files in the `eeg-notebooks/data` directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "inputHidden": false,
    "outputHidden": false
   },
   "outputs": [],
   "source": [
    "recording_path = os.path.join(\"C:\\\\RESEARCH\\\\MASTERTHESISDATA\\\\STUDYA\\\\\",  \"subject\" + str(subject), \"session\" + str(session), (\"recording_%s.csv\" %\n",
    "                                              strftime(\"%Y-%m-%d-%H.%M.%S\", gmtime())) )\n",
    "\n",
    "print('Recording data to: ', recording_path)\n",
    "\n",
    "stimulus = Process(target=Independentstudy.present, args=(duration,))\n",
    "#recording = Process(target=record, args=(duration, recording_path))\n",
    "\n",
    "stimulus.start()\n",
    "#recording.start()"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "mne"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "nteract": {
   "version": "0.8.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
